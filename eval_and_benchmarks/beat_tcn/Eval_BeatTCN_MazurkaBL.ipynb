{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b03b2d0",
   "metadata": {},
   "source": [
    "# Train & 5-Fold Evaluation for TCN + DBN\n",
    "\n",
    "Simply run all blocks in this Jupyter Notebook to execute 5-fold cross-validation training and evaluation for our TCN-based tempo, beat, and downbeat estimator. You'll find final performance metrics in the last code block.\n",
    "\n",
    "**Setup Reminder:**\n",
    "1. Ensure you've properly set up the `mirdata` module as described in **README.md**.\n",
    "2. Modify **Step 2**: Update the path to your `mazurkaBL.h5` dataset (preprocessed using `data_preprocess.ipynb`).\n",
    "3. Modify **Step 3**: Adjust your 5-fold split (`csv_dir` and `csv_filename`) to match your directory structure.\n",
    "\n",
    "**Acknowledgements:**\n",
    "This notebook builds upon and extends previous open-source work & TCN paper.\n",
    "- **S. Böck & M. E. P. Davies**, *Tempo, Beat, and Downbeat Tutorial* (2020). [eBook](https://tempobeatdownbeat.github.io/tutorial/intro.html)\n",
    "- **S. Böck & M. E. P. Davies (2020)**, *Deconstruct, Analyse, Reconstruct: How to Improve Tempo, Beat, and Downbeat Estimation*, *Proc. ISMIR*, pp. 574–582. [Paper](https://program.ismir2020.net/static/final_papers/223.pdf)\n",
    "\n",
    "**Modification:** \n",
    "1. We remove the tempo estimation branch from the TCN, since the MazuraBL dataset not contain tempo annotation.\n",
    "2. We modify the params of DBN Downbeat Tracker, since all MazurkaBL music are 3 beats per bar, each bar one downbeat.\n",
    "\n",
    "# 5-Fold Cross-validation Results of TCN on MazurkaBL Dataset\n",
    "**Step 5 Results Summary (step-by-step run this code notebook to get these results)**\n",
    "| Fold | Beat F1 (FINAL) | Beat F1 (BEST - reported) | Downbeat F1 (FINAL) | Downbeat F1 (BEST - reported) |\n",
    "|------|----------------|-----------------|--------------------|---------------------|\n",
    "| 0    | 0.6286         | 0.6287          | 0.3072             | 0.3090              |\n",
    "| 1    | 0.6113         | 0.6108          | 0.3053             | 0.3074              |\n",
    "| 2    | 0.5771         | 0.5792          | 0.2817             | 0.2814              |\n",
    "| 3    | 0.6199         | 0.6250          | 0.3172             | 0.3206              |\n",
    "| 4    | 0.6026         | 0.6031          | 0.2989             | 0.2992              |\n",
    "| **Avg ± Std** | 0.6079 ± 0.0177 | **0.6094 ± 0.0177** | 0.3020 ± 0.0118 | **0.3035 ± 0.0130** |\n",
    "\n",
    "**(Step 6 We verified our reproduced TCN has similar performance on GTZAN dataset as Böck et al., refer to their [Colab_Notebook](https://colab.research.google.com/drive/1tuOqNyO9gdMmYJsj33fP_QOfpRsm2tmt?usp=sharing))**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b8aa71",
   "metadata": {
    "id": "68b8aa71"
   },
   "source": [
    "## 1. Setup Environment (show package-versions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0aa4124d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.9.23 | Linux-6.8.0-60-generic-x86_64-with-glibc2.35\n",
      "Interpreter: /media/datadisk/home/22828187/conda_env/miniconda3/envs/beat_mir/bin/python\n",
      "numpy                -> 1.23.5                    | /media/datadisk/home/22828187/conda_env/miniconda3/envs/beat_mir/lib/python3.9/site-packages/numpy/__init__.py\n",
      "tensorflow           -> 2.15.1                    | /media/datadisk/home/22828187/conda_env/miniconda3/envs/beat_mir/lib/python3.9/site-packages/tensorflow/__init__.py\n",
      "keras                -> 2.15.0                    | /media/datadisk/home/22828187/conda_env/miniconda3/envs/beat_mir/lib/python3.9/site-packages/keras/__init__.py\n",
      "tensorflow_addons    -> 0.23.0                    | /media/datadisk/home/22828187/conda_env/miniconda3/envs/beat_mir/lib/python3.9/site-packages/tensorflow_addons/__init__.py\n",
      "librosa              -> 0.10.2                    | /media/datadisk/home/22828187/conda_env/miniconda3/envs/beat_mir/lib/python3.9/site-packages/librosa/__init__.py\n",
      "madmom               -> 0.16.1                    | /media/datadisk/home/22828187/conda_env/miniconda3/envs/beat_mir/lib/python3.9/site-packages/madmom/__init__.py\n",
      "mir_eval             -> 0.8.2                     | /media/datadisk/home/22828187/conda_env/miniconda3/envs/beat_mir/lib/python3.9/site-packages/mir_eval/__init__.py\n",
      "mirdata              -> 1.0.0rc1                  | /media/datadisk/home/22828187/zhanh/piano-dynamic-estimation/eval_and_benchmarks/beat_tcn/mirdata-repo/mirdata/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import os, sys, platform, importlib, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import madmom\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "from scipy.ndimage import maximum_filter1d\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import argrelmax\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from keras.utils import Sequence\n",
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "# Only print ERROR, ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  \n",
    "\n",
    "def where(mod):\n",
    "    try:\n",
    "        m = importlib.import_module(mod)\n",
    "        return getattr(m, \"__version__\", \"unknown\"), getattr(m, \"__file__\", \"n/a\")\n",
    "    except Exception as e:\n",
    "        return f\"IMPORT FAILED: {type(e).__name__}: {e}\", \"n/a\"\n",
    "\n",
    "print(\"Python:\", sys.version.split()[0], \"|\", platform.platform())\n",
    "print(\"Interpreter:\", sys.executable)\n",
    "\n",
    "for mod in [\"numpy\", \"tensorflow\", \"keras\", \"tensorflow_addons\",\n",
    "            \"librosa\", \"madmom\", \"mir_eval\", \"mirdata\"]:\n",
    "    ver, path = where(mod)\n",
    "    print(f\"{mod:20s} -> {ver:25s} | {path}\")\n",
    "\n",
    "# Limit the GPU occupancy of Tensorflow\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881b9226",
   "metadata": {
    "id": "881b9226"
   },
   "source": [
    "## 2. Load MazurkaBL (packed h5 files) with mirdata\n",
    "- `TO BE Modify: make the pre-processed mazurkaBL.h5 data_home path match yours.`\n",
    "- data_home=\"/media/datadisk/home/22828187/zhanh/202505_dynest_data/workspaces/hdf5s/mazurka_sr22050\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf7d33f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num tracks: 1999\n",
      "sample ids: ['mazurka06-1/pid1263-01', 'mazurka06-1/pid52932-01', 'mazurka06-1/pid9048-01', 'mazurka06-1/pid9050-01', 'mazurka06-1/pid9054-01']\n"
     ]
    }
   ],
   "source": [
    "from mirdata.datasets import mazurka_h5\n",
    "mazurka = mazurka_h5.Dataset(version=\"local\", data_home=\"/media/datadisk/home/22828187/zhanh/202505_dynest_data/workspaces/hdf5s/mazurka_sr22050\")\n",
    "tracks = mazurka.load_tracks() # for training\n",
    "print(\"num tracks:\", len(mazurka.track_ids))\n",
    "print(\"sample ids:\", mazurka.track_ids[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785c454c",
   "metadata": {
    "id": "785c454c"
   },
   "source": [
    "## 3. Load the 5-fold splits via CSVs\n",
    "\n",
    "We follow a 5-fold cross validation protocol, same as other benchmark in our paper. All 1,999 Mazurka tracks are partitioned into 5 folds, each with its own CSV file. or each fold, one subset is used for testing, while the remaining four folds are used for training (excluded validation set). \n",
    " - `TO BE Modify: make the 5-fold split csv_dir & csv_filename match yours.`\n",
    " - csv_dir = \"/media/datadisk/home/22828187/zhanh/202505_dynest_data/workspaces\"\n",
    " - csv_files = sorted(glob(f\"{csv_dir}/split_5fold_fold*_seed86.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "51484ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_split(csv_path, mazurka):\n",
    "    \"\"\"Load a 5fold CSV, return train/valid/test list.\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df.columns = [c.strip().lower() for c in df.columns]\n",
    "\n",
    "    def to_track_id(row):\n",
    "        stem = Path(str(row[\"h5_name\"])).stem\n",
    "        opus = str(row[\"opus\"])\n",
    "        return f\"{opus}/{stem}\"\n",
    "\n",
    "    df[\"track_id\"] = df.apply(to_track_id, axis=1)\n",
    "\n",
    "    train_ids = df.loc[df[\"split\"].str.lower() == \"train\", \"track_id\"].tolist()\n",
    "    valid_ids = df.loc[df[\"split\"].str.lower().isin([\"valid\",\"val\"]), \"track_id\"].tolist()\n",
    "    test_ids  = df.loc[df[\"split\"].str.lower() == \"test\",  \"track_id\"].tolist()\n",
    "\n",
    "    all_ids = set(mazurka.track_ids)\n",
    "    for name, ids in {\"train\":train_ids, \"valid\":valid_ids, \"test\":test_ids}.items():\n",
    "        missing = [i for i in ids if i not in all_ids]\n",
    "        if missing:\n",
    "            print(f\"[WARN] Broken pro-precess h5 dataset, {csv_path} {name} has {len(missing)} ID not included.\")\n",
    "    return train_ids, valid_ids, test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e16e1ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: train=1184, valid=407, test=397\n",
      "Fold 1: train=1207, valid=374, test=407\n",
      "Fold 2: train=1208, valid=406, test=374\n",
      "Fold 3: train=1178, valid=404, test=406\n",
      "Fold 4: train=1187, valid=397, test=404\n"
     ]
    }
   ],
   "source": [
    "csv_dir = \"/media/datadisk/home/22828187/zhanh/202505_dynest_data/workspaces\"\n",
    "csv_files = sorted(glob(f\"{csv_dir}/split_5fold_fold*_seed86.csv\"))\n",
    "\n",
    "fold_splits = {}\n",
    "for f in csv_files:\n",
    "    fold = int(Path(f).stem.split(\"_fold\")[1].split(\"_\")[0])\n",
    "    train_ids, valid_ids, test_ids = load_split(f, mazurka)\n",
    "    fold_splits[fold] = {\"train\": train_ids, \"valid\": valid_ids, \"test\":  test_ids}\n",
    "    print(f\"Fold {fold}: train={len(train_ids)}, valid={len(valid_ids)}, test={len(test_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd15238",
   "metadata": {
    "id": "8bd15238"
   },
   "source": [
    "# 4. Define TCN Network, Audio Processor, and Model Prediction & Evalaution Functions\n",
    "\n",
    "We create a multi-task model to jointly predict tempo, beats and doenbeats, which mostly follows our ISMIR 2020 paper \"Deconstruct, analyse, reconstruct: how to improve tempo, beat, and downbeat estimation.\".\n",
    "\n",
    "The heart of the network is a TCN (temporal convolutional network) with 11 TCN layers with increasing dilation rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bfdab72a",
   "metadata": {
    "id": "bfdab72a"
   },
   "outputs": [],
   "source": [
    "#@title Define the TCN model\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Activation, Conv1D, Conv2D, MaxPooling2D, Reshape, Dropout, SpatialDropout1D, GaussianNoise, GlobalAveragePooling1D, Concatenate, Add\n",
    "\n",
    "def residual_block(x, i, activation, num_filters, kernel_size, padding, dropout_rate=0, name=''):\n",
    "    name = f\"{name}_dilation_{i}\"\n",
    "    res_x = Conv1D(num_filters, 1, padding='same', name=name + '_1x1_conv_residual')(x)\n",
    "\n",
    "    conv_1 = Conv1D(num_filters, kernel_size, dilation_rate=i,   padding=padding, name=name + '_dilated_conv_1')(x)\n",
    "    conv_2 = Conv1D(num_filters, kernel_size, dilation_rate=2*i, padding=padding, name=name + '_dilated_conv_2')(x)\n",
    "\n",
    "    concat = Concatenate(name=name + '_concat')([conv_1, conv_2])\n",
    "    x = Activation(activation, name=name + '_activation')(concat) \n",
    "    x = SpatialDropout1D(dropout_rate, name=f\"{name}_spatial_dropout_{dropout_rate}\")(x)\n",
    "    x = Conv1D(num_filters, 1, padding='same', name=name + '_1x1_conv')(x)\n",
    "\n",
    "    return Add(name=name + '_merge_residual')([res_x, x]), x\n",
    "\n",
    "class TCN:\n",
    "    def __init__(self, num_filters=20, kernel_size=5,\n",
    "                 dilations=[1,2,4,8,16,32,64,128,256,512,1024],\n",
    "                 activation='elu', padding='same', dropout_rate=0.15, name='tcn'):\n",
    "        if padding not in ('causal', 'same'):\n",
    "            raise ValueError(\"Only 'causal' or 'same' padding are compatible for this layer.\")\n",
    "        self.num_filters = num_filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.dilations = dilations\n",
    "        self.activation = activation\n",
    "        self.padding = padding\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.name = name\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        x = inputs\n",
    "        skip_connections = []\n",
    "        for i, nf in zip(self.dilations, self.num_filters):\n",
    "            x, skip_out = residual_block(\n",
    "                x, i, self.activation, nf, self.kernel_size, self.padding, self.dropout_rate, name=self.name\n",
    "            )\n",
    "            skip_connections.append(skip_out)\n",
    "        x = Activation(self.activation, name=self.name + '_activation')(x)\n",
    "        skip = Add(name=self.name + '_merge_skip_connections')(skip_connections)\n",
    "        return x, skip\n",
    "\n",
    "def create_model(input_shape, num_filters=20, num_dilations=11, kernel_size=5, activation='elu', dropout_rate=0.15):\n",
    "    inp = Input(shape=input_shape)\n",
    "\n",
    "    conv_1 = Conv2D(num_filters, (3, 3), padding='valid', name='conv_1_conv')(inp)\n",
    "    conv_1 = Activation(activation, name='conv_1_activation')(conv_1)\n",
    "    conv_1 = MaxPooling2D((1, 3), name='conv_1_max_pooling')(conv_1)\n",
    "    conv_1 = Dropout(dropout_rate, name='conv_1_dropout')(conv_1)\n",
    "\n",
    "    conv_2 = Conv2D(num_filters, (1, 10), padding='valid', name='conv_2_conv')(conv_1)\n",
    "    conv_2 = Activation(activation, name='conv_2_activation')(conv_2)\n",
    "    conv_2 = MaxPooling2D((1, 3), name='conv_2_max_pooling')(conv_2)\n",
    "    conv_2 = Dropout(dropout_rate, name='conv_2_dropout')(conv_2)\n",
    "\n",
    "    conv_3 = Conv2D(num_filters, (3, 3), padding='valid', name='conv_3_conv')(conv_2)\n",
    "    conv_3 = Activation(activation, name='conv_3_activation')(conv_3)\n",
    "    conv_3 = MaxPooling2D((1, 3), name='conv_3_max_pooling')(conv_3)\n",
    "    conv_3 = Dropout(dropout_rate, name='conv_3_dropout')(conv_3)\n",
    "\n",
    "    x = Reshape((-1, num_filters), name='tcn_input_reshape')(conv_3)\n",
    "\n",
    "    dilations = [2 ** i for i in range(num_dilations)]\n",
    "    tcn, skip = TCN(\n",
    "        num_filters=[num_filters] * len(dilations),\n",
    "        kernel_size=kernel_size,\n",
    "        dilations=dilations,\n",
    "        activation=activation,\n",
    "        padding='same',\n",
    "        dropout_rate=dropout_rate,\n",
    "    )(x)\n",
    "\n",
    "    beats = Dropout(dropout_rate, name='beats_dropout')(tcn)\n",
    "    beats = Dense(1, name='beats_dense')(beats)\n",
    "    beats = Activation('sigmoid', name='beats')(beats)\n",
    "\n",
    "    downbeats = Dropout(dropout_rate, name='downbeats_dropout')(tcn)\n",
    "    downbeats = Dense(1, name='downbeats_dense')(downbeats)\n",
    "    downbeats = Activation('sigmoid', name='downbeats')(downbeats)\n",
    "\n",
    "    # Remove tempo head as MazurkaBL dataset not contain tempo annotation\n",
    "    # tempo = Dropout(dropout_rate, name='tempo_dropout')(skip)\n",
    "    # tempo = GlobalAveragePooling1D(name='tempo_global_average_pooling')(tempo)\n",
    "    # tempo = GaussianNoise(dropout_rate, name='tempo_noise')(tempo)\n",
    "    # tempo = Dense(300, name='tempo_dense')(tempo)\n",
    "    # tempo = Activation('softmax', name='tempo')(tempo)\n",
    "    # return Model(inp, outputs=[beats, downbeats, tempo])\n",
    "    \n",
    "    return Model(inp, outputs=[beats, downbeats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e42e79c1",
   "metadata": {
    "cellView": "form",
    "id": "e42e79c1"
   },
   "outputs": [],
   "source": [
    "#@title PreProcessor - STFT Transform, cnn_pad and infer_tempo\n",
    "from madmom.processors import ParallelProcessor, SequentialProcessor\n",
    "from madmom.audio.signal import SignalProcessor, FramedSignalProcessor\n",
    "from madmom.audio.stft import ShortTimeFourierTransformProcessor\n",
    "from madmom.audio.spectrogram import FilteredSpectrogramProcessor, LogarithmicSpectrogramProcessor\n",
    "\n",
    "# Use same audio pre-processing FFT params of our MazurkaBL.h5 files\n",
    "FPS = 50\n",
    "FFT_SIZE = 1024\n",
    "SAMPLE_RATE = 22050\n",
    "\n",
    "# Default Params of TCN on GTZAN (produce similar results as above params, but much more GPU Mem taken)\n",
    "# FPS = 100\n",
    "# FFT_SIZE = 2048\n",
    "# SAMPLE_RATE = 44100\n",
    "\n",
    "NUM_BANDS = 12\n",
    "MASK_VALUE = -1\n",
    "\n",
    "# define pre-processor\n",
    "class PreProcessor(SequentialProcessor):\n",
    "    def __init__(self, frame_size=FFT_SIZE, num_bands=NUM_BANDS, log=np.log, add=1e-6, fps=FPS):\n",
    "        sig = SignalProcessor(num_channels=1, sample_rate=SAMPLE_RATE)\n",
    "        frames = FramedSignalProcessor(frame_size=frame_size, fps=fps)\n",
    "        stft = ShortTimeFourierTransformProcessor()\n",
    "        filt = FilteredSpectrogramProcessor(num_bands=num_bands)\n",
    "        spec = LogarithmicSpectrogramProcessor(log=log, add=add)\n",
    "        super(PreProcessor, self).__init__((sig, frames, stft, filt, spec, np.array))\n",
    "        self.fps = fps\n",
    "\n",
    "\n",
    "def cnn_pad(data, pad_frames):\n",
    "    \"\"\"Pad the data by repeating the first and last frame N times.\"\"\"\n",
    "    pad_start = np.repeat(data[:1], pad_frames, axis=0)\n",
    "    pad_stop = np.repeat(data[-1:], pad_frames, axis=0)\n",
    "    return np.concatenate((pad_start, data, pad_stop))\n",
    "\n",
    "\n",
    "# def infer_tempo(beats, key=None, hist_smooth=15, fps=FPS, no_tempo=MASK_VALUE):\n",
    "#     ibis = np.diff(beats) * fps\n",
    "#     ibis_rounded = np.round(ibis).astype(int)\n",
    "#     bins = np.bincount(ibis_rounded)\n",
    "#     if not bins.any():\n",
    "#         return no_tempo\n",
    "#     if hist_smooth > 0:\n",
    "#         bins = madmom.audio.signal.smooth(bins, hist_smooth)\n",
    "#     intervals = np.arange(len(bins)) \n",
    "#     tempi = 60.0 * fps / intervals\n",
    "#     tempi[0] = 0 \n",
    "#     peaks = argrelmax(bins, mode='wrap')[0]\n",
    "#     if len(peaks) == 0:\n",
    "#         return no_tempo\n",
    "#     best = peaks[np.argmax(bins[peaks])]\n",
    "#     tempo_val = tempi[best]\n",
    "#     if not np.isfinite(tempo_val) or tempo_val <= 0:\n",
    "#         return no_tempo\n",
    "#     return tempo_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "60e0b955",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title DataSequence (new) - with widen functions restored\n",
    "# MazurkaBL dataset has no tempo annotation, we comment out this attribute\n",
    "class DataSequence(Sequence):\n",
    "    def __init__(self, tracks, pre_processor, num_tempo_bins=300, pad_frames=None,\n",
    "                 win_s=30.0, hop_s=30.0):\n",
    "        self.fps = pre_processor.fps\n",
    "        self.win = int(round(win_s * self.fps))\n",
    "        self.hop = int(round(hop_s * self.fps))\n",
    "        self.pad = pad_frames\n",
    "        self.X, self.Yb, self.Yd, self.Yt, self.segs = {}, {}, {}, {}, []\n",
    "        for key, t in tracks.items():\n",
    "            y, sr = t.audio\n",
    "            X = pre_processor(madmom.audio.Signal(y, sr)).astype('float32')\n",
    "            T = len(X)\n",
    "            bs = t.beats.times\n",
    "            beat = madmom.utils.quantize_events(bs, fps=self.fps, length=T).astype('float32')\n",
    "            dbs = bs[t.beats.positions.astype(int) == 1]\n",
    "            downbeat = madmom.utils.quantize_events(dbs, fps=self.fps, length=T).astype('float32')\n",
    "            # tempo = int(round(infer_tempo(bs, key, fps=self.fps)))\n",
    "            # while tempo >= num_tempo_bins: tempo //= 2\n",
    "            # tempo = keras.utils.to_categorical(tempo, num_tempo_bins, dtype='float32')\n",
    "            # self.X[key], self.Yb[key], self.Yd[key], self.Yt[key] = X, beat, downbeat, tempo\n",
    "            self.X[key], self.Yb[key], self.Yd[key] = X, beat, downbeat\n",
    "            for s in range(0, T - self.win + 1, self.hop):\n",
    "                self.segs.append((key, s, s + self.win))\n",
    "        self.N = len(self.segs)\n",
    "\n",
    "    def __len__(self): return self.N\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        key, a, b = self.segs[i]\n",
    "        x = self.X[key][a:b]\n",
    "        if self.pad: x = cnn_pad(x, self.pad)\n",
    "        y = {\n",
    "            'beats':     self.Yb[key][a:b][None, ..., None],\n",
    "            'downbeats': self.Yd[key][a:b][None, ..., None],\n",
    "            # 'tempo':     self.Yt[key][None, ...]\n",
    "        }\n",
    "        return x[None, ..., None], y\n",
    "\n",
    "    # --- widen targets (Didn't applied this data augmentation in our work) ---\n",
    "    def widen_beat_targets(self, size=3, value=0.5):\n",
    "        for y in self.Yb.values():\n",
    "            if np.allclose(y, MASK_VALUE): continue\n",
    "            np.maximum(y, maximum_filter1d(y, size=size) * value, out=y)\n",
    "\n",
    "    def widen_downbeat_targets(self, size=3, value=0.5):\n",
    "        for y in self.Yd.values():\n",
    "            if np.allclose(y, MASK_VALUE): continue\n",
    "            np.maximum(y, maximum_filter1d(y, size=size) * value, out=y)\n",
    "\n",
    "    # def widen_tempo_targets(self, size=3, value=0.5):\n",
    "    #     for y in self.Yt.values():\n",
    "    #         if np.allclose(y, MASK_VALUE): continue\n",
    "    #         np.maximum(y, maximum_filter1d(y, size=size) * value, out=y)\n",
    "\n",
    "    def append(self, other):\n",
    "        assert not any(k in self.X for k in other.X), 'IDs must be unique'\n",
    "        self.X.update(other.X)\n",
    "        self.Yb.update(other.Yb)\n",
    "        self.Yd.update(other.Yd)\n",
    "        # self.Yt.update(other.Yt)\n",
    "        self.segs.extend(other.segs)\n",
    "        self.N = len(self.segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "19faeb06",
   "metadata": {
    "cellView": "form",
    "id": "19faeb06"
   },
   "outputs": [],
   "source": [
    "#@title Masked Loss code based on: https://github.com/keras-team/keras/issues/3893\n",
    "def build_masked_loss(loss_function, mask_value=MASK_VALUE):\n",
    "    \"\"\"Builds a loss function that masks based on targets\n",
    "\n",
    "    Args:\n",
    "        loss_function: The loss function to mask\n",
    "        mask_value: The value to mask in the targets\n",
    "\n",
    "    Returns:\n",
    "        function: a loss function that acts like loss_function with masked inputs\n",
    "    \"\"\"\n",
    "\n",
    "    def masked_loss_function(y_true, y_pred):\n",
    "        mask = K.cast(K.not_equal(y_true, mask_value), K.floatx())\n",
    "        return loss_function(y_true * mask, y_pred * mask)\n",
    "\n",
    "    return masked_loss_function\n",
    "\n",
    "\n",
    "def masked_accuracy(y_true, y_pred):\n",
    "    total = K.sum(K.not_equal(y_true, MASK_VALUE))\n",
    "    correct = K.sum(K.equal(y_true, K.round(y_pred)))\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "41dfe64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Func for Model Prediction & Evaluation  (tempo head removed)\n",
    "def predict_beats_downbeats(model, dataset, fps=FPS, dedup_frames=2, desc=\"Predicting\"):\n",
    "    fps = getattr(dataset, \"fps\", getattr(getattr(dataset, \"pp\", None), \"fps\", fps))\n",
    "    dedup_sec = dedup_frames / float(fps)\n",
    "    # Performance: min_bpm 55 < 75 < 90\n",
    "    # Performance: max_bpm 240 = 215 > 200 > 180\n",
    "    \n",
    "    def _beat_tracker(beats_act):\n",
    "        proc = madmom.features.beats.DBNBeatTrackingProcessor(\n",
    "            min_bpm=90.0, max_bpm=215.0, fps=fps, transition_lambda=100, threshold=0.05)\n",
    "        return proc(beats_act)\n",
    "\n",
    "    def _downbeat_tracker(beats_act, downbeats_act):\n",
    "        combined = np.vstack([np.maximum(beats_act - downbeats_act, 0.0), downbeats_act]).T\n",
    "        proc = madmom.features.downbeats.DBNDownBeatTrackingProcessor(\n",
    "            beats_per_bar=[3], min_bpm=90.0, max_bpm=215.0, fps=fps, transition_lambda=100)\n",
    "        out = proc(combined)\n",
    "        return out[:, 0] if len(out) else np.empty((0,), dtype=float)\n",
    "\n",
    "    def _merge_segments(times_list):\n",
    "        if not times_list: return np.empty((0,), dtype=float)\n",
    "        t = np.sort(np.concatenate(times_list))\n",
    "        if len(t) == 0: return t\n",
    "        keep = [t[0]]\n",
    "        for x in t[1:]:\n",
    "            if x - keep[-1] >= dedup_sec:\n",
    "                keep.append(x)\n",
    "        return np.asarray(keep)\n",
    "\n",
    "    beats_buf, down_buf = {}, {}\n",
    "\n",
    "    for i in tqdm(range(len(dataset)), desc=desc):\n",
    "        # If this song needs to be separated into 30s segments\n",
    "        if hasattr(dataset, \"segs\"):\n",
    "            k, a, b = dataset.segs[i]          # a,b are frame indices\n",
    "            offset_sec = a / float(fps)        # Start-time offset\n",
    "        else:\n",
    "            # This song is already in 30s segments format\n",
    "            k = dataset.ids[i]\n",
    "            offset_sec = 0.0\n",
    "\n",
    "        x, _ = dataset[i]                      # x: (1, T, F, 1); labels ignored\n",
    "        # === tempo head removed: expect only two outputs ===\n",
    "        b_act, d_act = model.predict(x, verbose=0)   # (1, T, 1) each\n",
    "        b_act = b_act.squeeze()\n",
    "        d_act = d_act.squeeze()\n",
    "\n",
    "        # ---- Add the start-time offset into the detected results ----\n",
    "        bt = _beat_tracker(b_act) + offset_sec\n",
    "        dbt = _downbeat_tracker(b_act, d_act) + offset_sec\n",
    "\n",
    "        beats_buf.setdefault(k, []).append(bt)\n",
    "        down_buf.setdefault(k, []).append(dbt)\n",
    "\n",
    "    detections = {\n",
    "        k: {\n",
    "            \"beats\": _merge_segments(beats_buf[k]),\n",
    "            \"downbeats\": _merge_segments(down_buf.get(k, [])),\n",
    "        }\n",
    "        for k in beats_buf\n",
    "    }\n",
    "    return detections\n",
    "\n",
    "\n",
    "def evaluate_beats_and_downbeats(detections, beat_ann, downbeat_ann):\n",
    "    \"\"\"\n",
    "    detections:   dict[key] -> {'beats': 1D np.ndarray(sec), 'downbeats': 1D np.ndarray(sec)}\n",
    "    beat_ann:     dict[key] -> 1D np.ndarray(sec) of reference beat times\n",
    "    downbeat_ann: dict[key] -> 1D np.ndarray(sec) of reference downbeat times\n",
    "    Returns: {\"beat\": BeatMeanEvaluation or None, \"downbeat\": BeatMeanEvaluation or None}\n",
    "    \"\"\"\n",
    "    beat_evals, down_evals = [], []\n",
    "    for k, det in detections.items():\n",
    "        if k in beat_ann:\n",
    "            beat_evals.append(madmom.evaluation.beats.BeatEvaluation(det['beats'], beat_ann[k]))\n",
    "        if k in downbeat_ann:\n",
    "            down_evals.append(madmom.evaluation.beats.BeatEvaluation(det['downbeats'], downbeat_ann[k], downbeats=True))\n",
    "    beat_mean     = madmom.evaluation.beats.BeatMeanEvaluation(beat_evals) if beat_evals else None\n",
    "    downbeat_mean = madmom.evaluation.beats.BeatMeanEvaluation(down_evals) if down_evals else None\n",
    "    if beat_mean:\n",
    "        print(\"\\nBeat evaluation\"); print(beat_mean)\n",
    "    if downbeat_mean:\n",
    "        print(\"\\nDownbeat evaluation\"); print(downbeat_mean)\n",
    "    return {\"beat\": beat_mean, \"downbeat\": downbeat_mean}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8deed7b",
   "metadata": {
    "id": "f8deed7b"
   },
   "source": [
    "# 5. Run 5-Fold Train & Evaluation for TCN\n",
    "\n",
    "This notebook trains a TCN model (beat / downbeat / tempo heads) with **5-fold** splits.  \n",
    "For each fold, we train up to 100 epochs with validation-based early stopping, save the best checkpoint, then evaluate on the test split and finally report the **mean ± std** across folds.\n",
    "\n",
    "### Before running: ensure *Paths** and **Training Hyper-Params (optional)**\n",
    "- `PreProcessor` sample rate / FPS if needed.\n",
    "- `mazurka_h5` data path (your local H5 root).\n",
    "- 5-fold CSV path(s) for `train/valid/test`.\n",
    "- `epochs` (default 100), optimizer / LR, and callbacks.\n",
    "\n",
    "### Workflow of code below\n",
    "1. Build `train / valid / test` from the selected fold.\n",
    "2. Create `DataSequence` (segments = 30 s, no augmentation).\n",
    "3. `model.fit(...)` with `ModelCheckpoint` (best **val loss**), `ReduceLROnPlateau`, `EarlyStopping`, `TensorBoard`.\n",
    "4. Load `model_best.h5`, run inference, track beats & downbeats via madmom DBN, and evaluate.\n",
    "5. Repeat for all 5 folds and print averaged F1 (beat & downbeat).\n",
    "\n",
    "> Tip: keep training and evaluation in **separate cells** to keep logs clean.  \n",
    "> Output checkpoints are saved under `checkpoint/fold{i}_eps{epochs}/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0e281e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= 5-FOLD TRAINING (save BEST & FINAL ckpt, not use data augmentation) =========\n",
    "epochs, pad_frames = 120, 2\n",
    "ckpt_root = Path.cwd() / \"checkpoint\"\n",
    "\n",
    "for fold in range(5):\n",
    "      print(f\"\\n=== TRAIN fold {fold} ===\")\n",
    "      train_ids = fold_splits[fold][\"train\"]\n",
    "      valid_ids = fold_splits[fold][\"valid\"]\n",
    "\n",
    "      pp = PreProcessor()\n",
    "      train = DataSequence({k: tracks[k] for k in train_ids}, pre_processor=pp, pad_frames=pad_frames)\n",
    "      valid = DataSequence({k: tracks[k] for k in valid_ids}, pre_processor=pp, pad_frames=pad_frames)\n",
    "\n",
    "      input_shape = (None,) + train[0][0].shape[-2:]\n",
    "      model = create_model(input_shape)\n",
    "      model.compile(optimizer=keras.optimizers.Adam(1e-3),\n",
    "                  loss=[build_masked_loss(K.binary_crossentropy)]*2,   # beat + downbeat loss\n",
    "                  # loss=[build_masked_loss(K.binary_crossentropy)]*3, # tempo loss removed\n",
    "                  metrics=['binary_accuracy'])\n",
    "      outdir = ckpt_root / f\"fold{fold}_eps{epochs}\"\n",
    "      outdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "      cb = [keras.callbacks.ModelCheckpoint(str(outdir/\"model_best.h5\"),save_best_only=True, monitor=\"val_loss\"),\n",
    "            keras.callbacks.ReduceLROnPlateau(patience=10, factor=0.2, min_lr=1e-7, monitor=\"val_loss\", verbose=1),\n",
    "            keras.callbacks.EarlyStopping(patience=80, monitor=\"val_loss\"),\n",
    "            CSVLogger(str(outdir/\"train_log.txt\"), append=True, separator=\"\\t\")]\n",
    "      model.fit(train, validation_data=valid, epochs=epochs, callbacks=cb, shuffle=True, verbose=1)\n",
    "      model.save(outdir/\"model_final.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d6024f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- EVAL fold 0 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 1992/1992 [01:48<00:00, 18.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Beat evaluation\n",
      "mean for 397 files\n",
      "  F-measure: 0.629 P-score: 0.635 Cemgil: 0.502 Goto: 0.010 CMLc: 0.043 CMLt: 0.403 AMLc: 0.051 AMLt: 0.422 D: 0.564 Dg: 0.393\n",
      "\n",
      "Downbeat evaluation\n",
      "mean for 397 files\n",
      "  F-measure: 0.307 P-score: 0.334 Cemgil: 0.246 Goto: 0.000 CMLc: 0.001 CMLt: 0.001 AMLc: 0.088 AMLt: 0.467 D: 0.552 Dg: 0.320\n",
      "Fold 0  [BEST ] Beat F1: 0.6286 | Downbeat F1: 0.3072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 1992/1992 [01:49<00:00, 18.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Beat evaluation\n",
      "mean for 397 files\n",
      "  F-measure: 0.629 P-score: 0.636 Cemgil: 0.501 Goto: 0.010 CMLc: 0.043 CMLt: 0.404 AMLc: 0.051 AMLt: 0.422 D: 0.566 Dg: 0.392\n",
      "\n",
      "Downbeat evaluation\n",
      "mean for 397 files\n",
      "  F-measure: 0.309 P-score: 0.334 Cemgil: 0.246 Goto: 0.000 CMLc: 0.001 CMLt: 0.001 AMLc: 0.090 AMLt: 0.468 D: 0.558 Dg: 0.323\n",
      "Fold 0  [FINAL] Beat F1: 0.6287 | Downbeat F1: 0.3090\n",
      "\n",
      "--- EVAL fold 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 2252/2252 [02:01<00:00, 18.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Beat evaluation\n",
      "mean for 407 files\n",
      "  F-measure: 0.611 P-score: 0.626 Cemgil: 0.486 Goto: 0.002 CMLc: 0.037 CMLt: 0.387 AMLc: 0.050 AMLt: 0.419 D: 0.572 Dg: 0.396\n",
      "\n",
      "Downbeat evaluation\n",
      "mean for 407 files\n",
      "  F-measure: 0.305 P-score: 0.336 Cemgil: 0.245 Goto: 0.000 CMLc: 0.001 CMLt: 0.002 AMLc: 0.075 AMLt: 0.440 D: 0.549 Dg: 0.309\n",
      "Fold 1  [BEST ] Beat F1: 0.6113 | Downbeat F1: 0.3053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 2252/2252 [02:07<00:00, 17.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Beat evaluation\n",
      "mean for 407 files\n",
      "  F-measure: 0.611 P-score: 0.625 Cemgil: 0.490 Goto: 0.002 CMLc: 0.038 CMLt: 0.388 AMLc: 0.051 AMLt: 0.420 D: 0.582 Dg: 0.407\n",
      "\n",
      "Downbeat evaluation\n",
      "mean for 407 files\n",
      "  F-measure: 0.307 P-score: 0.336 Cemgil: 0.249 Goto: 0.000 CMLc: 0.001 CMLt: 0.002 AMLc: 0.074 AMLt: 0.447 D: 0.562 Dg: 0.332\n",
      "Fold 1  [FINAL] Beat F1: 0.6108 | Downbeat F1: 0.3074\n",
      "\n",
      "--- EVAL fold 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 1944/1944 [01:46<00:00, 18.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Beat evaluation\n",
      "mean for 374 files\n",
      "  F-measure: 0.577 P-score: 0.619 Cemgil: 0.456 Goto: 0.005 CMLc: 0.046 CMLt: 0.381 AMLc: 0.052 AMLt: 0.393 D: 0.568 Dg: 0.351\n",
      "\n",
      "Downbeat evaluation\n",
      "mean for 374 files\n",
      "  F-measure: 0.282 P-score: 0.337 Cemgil: 0.223 Goto: 0.000 CMLc: 0.001 CMLt: 0.001 AMLc: 0.074 AMLt: 0.401 D: 0.458 Dg: 0.248\n",
      "Fold 2  [BEST ] Beat F1: 0.5771 | Downbeat F1: 0.2817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 1944/1944 [01:46<00:00, 18.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Beat evaluation\n",
      "mean for 374 files\n",
      "  F-measure: 0.579 P-score: 0.621 Cemgil: 0.458 Goto: 0.005 CMLc: 0.046 CMLt: 0.383 AMLc: 0.052 AMLt: 0.396 D: 0.572 Dg: 0.361\n",
      "\n",
      "Downbeat evaluation\n",
      "mean for 374 files\n",
      "  F-measure: 0.281 P-score: 0.337 Cemgil: 0.223 Goto: 0.000 CMLc: 0.001 CMLt: 0.001 AMLc: 0.075 AMLt: 0.405 D: 0.462 Dg: 0.251\n",
      "Fold 2  [FINAL] Beat F1: 0.5792 | Downbeat F1: 0.2814\n",
      "\n",
      "--- EVAL fold 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 2137/2137 [02:41<00:00, 13.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Beat evaluation\n",
      "mean for 406 files\n",
      "  F-measure: 0.620 P-score: 0.591 Cemgil: 0.501 Goto: 0.000 CMLc: 0.040 CMLt: 0.355 AMLc: 0.063 AMLt: 0.421 D: 0.572 Dg: 0.379\n",
      "\n",
      "Downbeat evaluation\n",
      "mean for 406 files\n",
      "  F-measure: 0.317 P-score: 0.333 Cemgil: 0.257 Goto: 0.000 CMLc: 0.002 CMLt: 0.003 AMLc: 0.073 AMLt: 0.400 D: 0.564 Dg: 0.331\n",
      "Fold 3  [BEST ] Beat F1: 0.6199 | Downbeat F1: 0.3172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 2137/2137 [01:59<00:00, 17.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Beat evaluation\n",
      "mean for 406 files\n",
      "  F-measure: 0.625 P-score: 0.596 Cemgil: 0.507 Goto: 0.002 CMLc: 0.042 CMLt: 0.362 AMLc: 0.063 AMLt: 0.422 D: 0.585 Dg: 0.392\n",
      "\n",
      "Downbeat evaluation\n",
      "mean for 406 files\n",
      "  F-measure: 0.321 P-score: 0.333 Cemgil: 0.260 Goto: 0.000 CMLc: 0.002 CMLt: 0.003 AMLc: 0.073 AMLt: 0.409 D: 0.577 Dg: 0.340\n",
      "Fold 3  [FINAL] Beat F1: 0.6250 | Downbeat F1: 0.3206\n",
      "\n",
      "--- EVAL fold 4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 1746/1746 [01:58<00:00, 14.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Beat evaluation\n",
      "mean for 404 files\n",
      "  F-measure: 0.603 P-score: 0.613 Cemgil: 0.474 Goto: 0.007 CMLc: 0.041 CMLt: 0.367 AMLc: 0.050 AMLt: 0.387 D: 0.543 Dg: 0.328\n",
      "\n",
      "Downbeat evaluation\n",
      "mean for 404 files\n",
      "  F-measure: 0.299 P-score: 0.337 Cemgil: 0.237 Goto: 0.000 CMLc: 0.001 CMLt: 0.001 AMLc: 0.076 AMLt: 0.416 D: 0.513 Dg: 0.275\n",
      "Fold 4  [BEST ] Beat F1: 0.6026 | Downbeat F1: 0.2989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 1746/1746 [02:13<00:00, 13.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Beat evaluation\n",
      "mean for 404 files\n",
      "  F-measure: 0.603 P-score: 0.613 Cemgil: 0.475 Goto: 0.007 CMLc: 0.041 CMLt: 0.367 AMLc: 0.051 AMLt: 0.388 D: 0.547 Dg: 0.328\n",
      "\n",
      "Downbeat evaluation\n",
      "mean for 404 files\n",
      "  F-measure: 0.299 P-score: 0.336 Cemgil: 0.237 Goto: 0.000 CMLc: 0.001 CMLt: 0.001 AMLc: 0.076 AMLt: 0.420 D: 0.521 Dg: 0.284\n",
      "Fold 4  [FINAL] Beat F1: 0.6031 | Downbeat F1: 0.2992\n"
     ]
    }
   ],
   "source": [
    "# ========= 5-FOLD Evaluation (report BEST & FINAL) =========\n",
    "beat_ann     = {k: v.beats.times for k, v in tracks.items() if v.beats is not None}\n",
    "downbeat_ann = {k: v.beats.times[v.beats.positions.astype(int)==1] for k, v in tracks.items() if v.beats is not None}\n",
    "\n",
    "epochs, pad_frames = 120, 2\n",
    "ckpt_root = Path.cwd() / \"checkpoint\"\n",
    "\n",
    "summary_best_beats, summary_best_down = [], []\n",
    "summary_final_beats, summary_final_down = [], []\n",
    "\n",
    "for fold in range(5):\n",
    "    print(f\"\\n--- EVAL fold {fold} ---\")\n",
    "    pp = PreProcessor()\n",
    "    test_ids = fold_splits[fold][\"test\"]\n",
    "    test = DataSequence({k: tracks[k] for k in test_ids}, pre_processor=pp, pad_frames=pad_frames)\n",
    "\n",
    "    input_shape = (None,) + test[0][0].shape[-2:]\n",
    "    model = create_model(input_shape)\n",
    "    model.compile(optimizer=\"adam\",\n",
    "                    loss=[build_masked_loss(K.binary_crossentropy)]*2,\n",
    "                    metrics=['binary_accuracy'])\n",
    "                    # loss=[build_masked_loss(K.binary_crossentropy)]*3, # tempo head removed\n",
    "\n",
    "    outdir = ckpt_root / f\"fold{fold}_eps{epochs}\"\n",
    "\n",
    "    # --- BEST ---\n",
    "    model.load_weights(str(outdir / \"model_best.h5\"))\n",
    "    detections = predict_beats_downbeats(model, test, fps=pp.fps)\n",
    "    scores = evaluate_beats_and_downbeats(detections, beat_ann, downbeat_ann)\n",
    "    b_f1_best, d_f1_best = float(scores[\"beat\"].fmeasure), float(scores[\"downbeat\"].fmeasure)\n",
    "    print(f\"Fold {fold}  [BEST ] Beat F1: {b_f1_best:.4f} | Downbeat F1: {d_f1_best:.4f}\")\n",
    "    summary_best_beats.append(b_f1_best); summary_best_down.append(d_f1_best)\n",
    "\n",
    "    # --- FINAL ---\n",
    "    model.load_weights(str(outdir / \"model_final.h5\"))\n",
    "    detections = predict_beats_downbeats(model, test, fps=pp.fps)\n",
    "    scores = evaluate_beats_and_downbeats(detections, beat_ann, downbeat_ann)\n",
    "    b_f1_final, d_f1_final = float(scores[\"beat\"].fmeasure), float(scores[\"downbeat\"].fmeasure)\n",
    "    print(f\"Fold {fold}  [FINAL] Beat F1: {b_f1_final:.4f} | Downbeat F1: {d_f1_final:.4f}\")\n",
    "    summary_final_beats.append(b_f1_final); summary_final_down.append(d_f1_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e5acd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 5-Fold Summary (F-measure) (90,215) ===\n",
      "[FINAL Model over 120 epochs]  Beat F1   : 0.6079 ± 0.0177\n",
      "[FINAL ] Downbeat : 0.3020 ± 0.0118\n",
      "[BEST Model over 120 epochs] Beat F1   : 0.6094 ± 0.0177\n",
      "[BEST] Downbeat : 0.3035 ± 0.0130\n"
     ]
    }
   ],
   "source": [
    "# ========= 5-FOLD Summary =========\n",
    "print(\"\\n=== 5-Fold Summary (F-measure) (90,215) ===\")\n",
    "print(f\"[FINAL Model over 120 epochs] Beat F1   : {np.mean(summary_final_beats):.4f} ± {np.std(summary_final_beats):.4f}\")\n",
    "print(f\"[FINAL] Downbeat : {np.mean(summary_final_down):.4f} ± {np.std(summary_final_down):.4f}\")\n",
    "print(f\"[BEST Model over 120 epochs]  Beat F1   : {np.mean(summary_best_beats):.4f} ± {np.std(summary_best_beats):.4f}\")\n",
    "print(f\"[BEST ] Downbeat : {np.mean(summary_best_down):.4f} ± {np.std(summary_best_down):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc2cf73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 65,962 params  (0.3 MiB)\n"
     ]
    }
   ],
   "source": [
    "total_params = model.count_params()\n",
    "param_size_mib = total_params * 4 / 1024**2  # float32 storage size\n",
    "print(f\"Total params: {total_params:,} params  ({param_size_mib:.1f} MiB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d8d8cc",
   "metadata": {},
   "source": [
    "### 62,962 params >> 0.065 M params >> 0.1 Params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c708dc",
   "metadata": {},
   "source": [
    "### Note on DBN Parameter Adjustment\n",
    "\n",
    "We adjusted the parameters of the **Dynamic Bayesian Network (DBN)** used for beat and downbeat tracking.  \n",
    "For traditional machine learning algorithms, **parameter tuning is essential** for achieving optimal performance.  \n",
    "However, this also implies that such models often **generalize poorly** across datasets — each dataset tends to have its own \"best\" set of parameters.\n",
    "\n",
    "In our case, we modified the DBN beat/downbeat tracker settings:  \n",
    "- `min_bpm = 90.0` (best observed; we tested [20, 40, 55, 75, 95, 105])  \n",
    "- `max_bpm = 215.0` (best observed; we tested [150, 180, 200, 215, 240, 275, 300])  \n",
    "\n",
    "These adjustments improved results on MazurkaBL dataset but also emphasize the **dataset-specific sensitivity** of DBN approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a3534e",
   "metadata": {},
   "source": [
    "# Backup: Verify our reproduced TCN with GTZAN-mini\n",
    "\n",
    "Our TCN + DBN implementation achieves performance on GTZAN-mini that is **consistent with the results reported by Böck et al.**, confirming the correctness of our reimplementation. [Colab Notebook of Published TCN w. GTZAN-mini](https://colab.research.google.com/drive/1tuOqNyO9gdMmYJsj33fP_QOfpRsm2tmt?usp=sharing) \n",
    "\n",
    "---\n",
    "\n",
    "**Acknowledgements**  \n",
    "- **S. Böck & M. E. P. Davies**, *Tempo, Beat, and Downbeat Tutorial* (2020). [eBook](https://tempobeatdownbeat.github.io/tutorial/intro.html)\n",
    "- **S. Böck & M. E. P. Davies (2020)**, *Deconstruct, Analyse, Reconstruct: How to Improve Tempo, Beat, and Downbeat Estimation*, *Proc. ISMIR*, pp. 574–582. [Paper](https://program.ismir2020.net/static/final_papers/223.pdf)\n",
    "\n",
    "---\n",
    "\n",
    "**DBN Tracker Settings for GTZAN-mini**: modify the beat/downbeat tracker settings in `predict_beats_downbeats` before the inference\n",
    "```python\n",
    "    def _beat_tracker(beats_act):\n",
    "        proc = madmom.features.beats.DBNBeatTrackingProcessor(\n",
    "            min_bpm=55.0, max_bpm=215.0, fps=fps, transition_lambda=100, threshold=0.05\n",
    "        ...\n",
    "    def _downbeat_tracker(beats_act, downbeats_act):\n",
    "        ...\n",
    "        proc = madmom.features.downbeats.DBNDownBeatTrackingProcessor(\n",
    "            beats_per_bar=[3, 4], min_bpm=55.0, max_bpm=215.0, fps=fps, transition_lambda=100\n",
    "        )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "172ecc7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Downloading ['mini', 'tempo_beat_annotations', 'index']. Index is being stored in /media/datadisk/home/22828187/zhanh/piano-dynamic-estimation/eval_and_benchmarks/beat_tcn/mirdata-repo/mirdata/datasets/indexes, and the rest of files in /home/22828187/mir_datasets/gtzan_genre\n",
      "WARNING: [mini] downloading main.zip\n",
      "WARNING: /home/22828187/mir_datasets/gtzan_genre/main.zip already exists and will not be downloaded. Rerun with force_overwrite=True to delete this file and force the download.\n",
      "WARNING: [tempo_beat_annotations] downloading annot.zip\n",
      "WARNING: /home/22828187/mir_datasets/gtzan_genre/annot.zip already exists and will not be downloaded. Rerun with force_overwrite=True to delete this file and force the download.\n",
      "WARNING: [index] downloading gtzan_genre_1.0_mini_index.json\n",
      "WARNING: /media/datadisk/home/22828187/zhanh/piano-dynamic-estimation/eval_and_benchmarks/beat_tcn/mirdata-repo/mirdata/datasets/indexes/gtzan_genre_1.0_mini_index.json already exists and will not be downloaded. Rerun with force_overwrite=True to delete this file and force the download.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 20 pop.00002\n"
     ]
    }
   ],
   "source": [
    "# ========= DOWNLOAD GTZAN MINI DATASET & RANDOM SPLIT =========\n",
    "import mirdata\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "gtzan = mirdata.initialize('gtzan_genre', version='mini')\n",
    "gtzan.download()\n",
    "tracks = gtzan.load_tracks()\n",
    "\n",
    "gtzan_train_files, gtzan_test_files = train_test_split(list(tracks.keys()), test_size=0.2, random_state=1234)\n",
    "print(len(gtzan_train_files), len(gtzan_test_files), gtzan_test_files[-1])\n",
    "\n",
    "train_ids = [x for x in gtzan_train_files]\n",
    "valid_ids =  [x for x in gtzan_test_files]\n",
    "test_ids = valid_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956f7b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= GTZAN TRAINING =========\n",
    "epochs, pad_frames = 120, 2\n",
    "ckpt_root = Path.cwd() / \"gtzan_checkpoint\"\n",
    "pp = PreProcessor()\n",
    "train = DataSequence({k: tracks[k] for k in train_ids}, pre_processor=pp, pad_frames=pad_frames)\n",
    "valid = DataSequence({k: tracks[k] for k in valid_ids}, pre_processor=pp, pad_frames=pad_frames)\n",
    "\n",
    "input_shape = (None,) + train[0][0].shape[-2:]\n",
    "model = create_model(input_shape)\n",
    "model.compile(optimizer=keras.optimizers.Adam(1e-3),\n",
    "              loss=[build_masked_loss(K.binary_crossentropy)]*2,\n",
    "              metrics=['binary_accuracy'])\n",
    "outdir = ckpt_root / f\"gtzan_eps{epochs}\"\n",
    "outdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "cb = [\n",
    "    keras.callbacks.ModelCheckpoint(str(outdir/\"model_best.h5\"), save_best_only=True, monitor=\"val_loss\"),\n",
    "    keras.callbacks.ReduceLROnPlateau(patience=10, factor=0.2, min_lr=1e-7, monitor=\"val_loss\"),\n",
    "    keras.callbacks.EarlyStopping(patience=80, monitor=\"val_loss\"),\n",
    "    CSVLogger(str(outdir/\"train_log.txt\"), append=True, separator=\"\\t\")\n",
    "]\n",
    "model.fit(train, validation_data=valid, epochs=epochs, callbacks=cb, shuffle=True, verbose=1)\n",
    "model.save(outdir/\"model_final.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9632df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 20/20 [00:03<00:00,  6.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Beat evaluation\n",
      "mean for 20 files\n",
      "  F-measure: 0.821 P-score: 0.799 Cemgil: 0.729 Goto: 0.700 CMLc: 0.613 CMLt: 0.645 AMLc: 0.854 AMLt: 0.892 D: 2.809 Dg: 1.634\n",
      "\n",
      "Downbeat evaluation\n",
      "mean for 20 files\n",
      "  F-measure: 0.305 P-score: 0.252 Cemgil: 0.272 Goto: 0.000 CMLc: 0.000 CMLt: 0.000 AMLc: 0.058 AMLt: 0.066 D: 2.512 Dg: 1.582\n",
      "Beat F1: 0.8208\n",
      "Downbeat F1: 0.3052\n"
     ]
    }
   ],
   "source": [
    "# ========= GTZAN EVALUATION =========\n",
    "beat_ann     = {k: v.beats.times for k, v in tracks.items() if v.beats is not None}\n",
    "downbeat_ann = {k: v.beats.times[v.beats.positions.astype(int)==1] for k, v in tracks.items() if v.beats is not None}\n",
    "\n",
    "pp = PreProcessor()\n",
    "test = DataSequence({k: tracks[k] for k in test_ids}, pre_processor=pp, pad_frames=pad_frames)\n",
    "\n",
    "test.widen_beat_targets()\n",
    "test.widen_downbeat_targets()\n",
    "\n",
    "input_shape = (None,) + test[0][0].shape[-2:]\n",
    "model = create_model(input_shape)\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=[build_masked_loss(K.binary_crossentropy)]*2,\n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "outdir = ckpt_root / f\"gtzan_eps{epochs}\"\n",
    "model.load_weights(str(outdir / \"model_best.h5\"))\n",
    "\n",
    "detections = predict_beats_downbeats(model, test, fps=pp.fps)\n",
    "scores = evaluate_beats_and_downbeats(detections, beat_ann, downbeat_ann)\n",
    "\n",
    "print(f\"Beat F1: {scores['beat'].fmeasure:.4f}\")\n",
    "print(f\"Downbeat F1: {scores['downbeat'].fmeasure:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "2dd60ea1",
    "8bd15238",
    "066a2505"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "beat_mir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
